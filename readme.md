**Trilha Pr√°tica GenAI com TypeScript: Da Teoria ao C√≥digo com LLMs**

**Objetivo:** Transformar seu aprendizado em experi√™ncia pr√°tica com LLMs e GenAI usando TypeScript. A trilha √© composta por 3 "mini cursos" com aplica√ß√£o real, n√≠vel crescente e tudo explicadinho: instala√ß√£o, c√≥digo, comandos, organiza√ß√£o, deploy e aprendizado aplicado.

---

## üß± N√≠vel 1: "Hello, LLM!" ‚Äì Primeiros Passos com OpenAI API e TypeScript

**Objetivo:** Aprender a integrar um modelo de linguagem (ChatGPT) com um script TypeScript simples.

### Pr√©-requisitos:

- Node.js 18+
- Conta na OpenAI ([https://platform.openai.com/](https://platform.openai.com/))

### Instala√ß√£o:

```bash
mkdir hello-llm && cd hello-llm
npm init -y
npm install openai dotenv
npm install --save-dev typescript ts-node @types/node
npx tsc --init
```

### Organiza√ß√£o de pastas:

```
hello-llm/
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ index.ts
‚îú‚îÄ‚îÄ tsconfig.json
‚îî‚îÄ‚îÄ package.json
```

### Arquivo `.env`:

```
OPENAI_API_KEY=sua-chave-aqui
```

### C√≥digo `index.ts`:

```ts
import { config } from 'dotenv';
import readline from 'readline';
import OpenAI from 'openai';

config();
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

const rl = readline.createInterface({ input: process.stdin, output: process.stdout });

function perguntar(prompt: string): void {
  rl.question(prompt, async (input) => {
    const chat = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: input }],
    });
    console.log('\nResposta:\n', chat.choices[0].message.content);
    perguntar('Voc√™: ');
  });
}

perguntar('Voc√™: ');
```

### Rodar:

```bash
npx ts-node index.ts
```

### Desafio pr√°tico:

- Fa√ßa o modelo responder a mesma pergunta com temperatura 0.2 e 0.9 (adicione o par√¢metro).
- Teste comandos como: "Explique RAG como se eu tivesse 5 anos".

---

## ‚öôÔ∏è N√≠vel 2: "Meu Primeiro Mini Agente" ‚Äì Criando uma API com Express + OpenAI

**Objetivo:** Criar uma API em Express com um endpoint que se comunica com o LLM.

### Instala√ß√£o:

```bash
mkdir mini-agent && cd mini-agent
npm init -y
npm install express openai dotenv
npm install --save-dev typescript ts-node nodemon @types/node @types/express
npx tsc --init
```

### Estrutura de pastas:

```
mini-agent/
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ index.ts
‚îú‚îÄ‚îÄ tsconfig.json
‚îî‚îÄ‚îÄ package.json
```

### C√≥digo `src/index.ts`:

```ts
import express from 'express';
import { config } from 'dotenv';
import OpenAI from 'openai';

config();
const app = express();
app.use(express.json());

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post('/ask', async (req, res) => {
  const { question } = req.body;
  const completion = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: question }],
  });
  res.json({ resposta: completion.choices[0].message.content });
});

app.listen(3000, () => console.log('Servidor rodando em http://localhost:3000'));
```

### Rodar servidor:

```bash
npx ts-node src/index.ts
```

### Testar:

- Via Postman ou curl:

```bash
curl -X POST http://localhost:3000/ask \
-H "Content-Type: application/json" \
-d '{ "question": "O que √© GenAI?" }'
```

### Desafio pr√°tico:

- Adicione uma rota `/resumir` que aceita um texto grande e retorna um resumo via LLM.

---

## üß† N√≠vel 3: "Agente com Mem√≥ria + Contexto" ‚Äì Construindo Agente com LangChain.js

**Objetivo:** Criar um agente com mem√≥ria de conversa e uso de contexto de documentos.

### Instala√ß√£o:

```bash
npm install langchain openai dotenv
```

### Organiza√ß√£o:

```
agente-contexto/
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ index.ts
‚îÇ   ‚îî‚îÄ‚îÄ artigo.txt
```

### C√≥digo `src/index.ts` (exemplo com mem√≥ria):

```ts
import { config } from 'dotenv';
import { ChatOpenAI } from 'langchain/chat_models/openai';
import { BufferMemory } from 'langchain/memory';
import { ConversationChain } from 'langchain/chains';
import readline from 'readline';

config();
const llm = new ChatOpenAI({ modelName: 'gpt-3.5-turbo', temperature: 0 });
const memory = new BufferMemory();
const chain = new ConversationChain({ llm, memory });

const rl = readline.createInterface({ input: process.stdin, output: process.stdout });

function prompt() {
  rl.question('Voc√™: ', async (input) => {
    const response = await chain.run(input);
    console.log('Agente:', response);
    prompt();
  });
}
prompt();
```

### Desafio pr√°tico:

- Fa√ßa ele lembrar do nome do usu√°rio ou prefer√™ncias ("me chame de Jean")
- Adicione um documento `.txt` e use como base de contexto com `DocumentLoader`

---

## Pr√≥ximos Passos

-

Se quiser, posso montar esse curso tamb√©m como workspace em Notion com etapas marc√°veis, c√≥digo e links. S√≥ dar o sinal!

